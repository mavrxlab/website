#  {#technology data-menu-title="The Technology" background="#9EABAE" background-image="assets/lab.png" background-size="35%" background-position="right 5% top 5%"}

[THE TECHNOLOGY]{.r-fit-text}

::: notes
Now that we have some ways of actually doing these things, let's try to bring it back to the technologies like Web3, XR, and artificial intelligence before we triangulate with education.
:::

## Web3 & XR

::: columns
::: {.column width="50%"}
![](assets/traditionalschooling.jpg){width="70%" fig-align="center"}
:::

::: {.column width="50%"}
![](assets/learninginfuture.jpg){width="70%" fig-align="center"}
:::
:::

::: attribution
:::

::: notes
I want to touch to Web3 and XR quickly before moving on to artificial intelligence because I think they'll both be providing a supporting role going forward. Let me explain.

Web3 is a catch-all term for, in short, a decentralized, blockchain-based internet. If you got a chance to check out Dagan's talk from yesterday, he did a great job explaining it, so I won't spend much time on it here. So, I'll just reiterate that it's meant to provide ownership and agency while increasing transparency, trust, and accessibility. My best advice when it comes to thinking about education and Web3 together is to divorce any thoughts of cryptocurrency from it and look solely and the utility of the technology. Okay, moving on.

XR, or extended reality, on the otherhand, has a much more intimate relationship with AI in the realm of pedagogy.(And this example is not intended to be abilist; extended reality is visual-heavy medium, however.) I'd like to paint a picture for you:

You're looking at a student. They're sitting in a chair, no desk in front of them, with their hands raised, moving as if directing an orchestra. Their eyes seem to be darting randomly and they repeatedly angle their head slightly in various directions. What do you imagine is going on?

In probably less time than you think, we won't need bulky headsets to engage with that augmented layer of reality that we talked about earlier. Instead, simply contacts will be enough. Perhaps a couple rings to make hand tracking easier.

There's still the question of what the learner is experiencing, though. Perhaps they're manipulating a photo-realistic human heart. Or a relief valve in a nuclear reactor. Or unearthing an artifact in the Saqqara necropolis. All of these are possible but, as it stands now, they all must be pre-developed. Somewhere within the process, someone had to sit down and code this experience into life. Think about all the curriculum you've designed, after all, just on paper. If there's narration or interactive instruction involved, doubly so. But what if that wasn't the case?
:::

## Artifical Intelligence

::: columns
::: {.column width="65%"}
-   Fears
-   Accessibility
-   Ethics
:::

::: {.column width="35%"}
![](assets/ai.jpg)
:::
:::

::: notes
Remember, AI is not smart. I like the Microsoft leader that said, "Artificial Intelligence is neither artificial nor intelligent." AI is just very confident but it's only as good as the input, right?
:::
