<!DOCTYPE html>
<html lang="en"><head>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/quarto-contrib/roughnotation-0.5.1/rough-notation.iife.js"></script>
<script src="../../../site_libs/quarto-contrib/roughnotation-init-1.0.0/rough.js"></script>
<link href="../../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.280">

  <meta name="author" content=" Ryan Straight, Ph.D ">
  <title>A Philosophy of Technology and Education in the Metaverse</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="../../../site_libs/quarto-diagram/mermaid.min.js"></script>
  <script src="../../../site_libs/quarto-diagram/mermaid-init.js"></script>
  <link href="../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<meta name="citation_title" content="&amp;amp;lt;img align=&amp;quot;center&quot; width=&quot;75%&quot; src=&quot;lab.png&quot;&amp;gt;
">
<meta name="citation_author" content="&amp;amp;lt;br /&amp;gt;**Ryan Straight, Ph.D**<br />">
<meta name="citation_fulltext_html_url" content="https://mavrxlab.org/news/2022-11-12-ed3-postphenom/deck">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Doing Postphenomenology in Education;,citation_author=Catherine Adams;,citation_author=Joni Turville;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_isbn=978-1-4985-4523-5;,citation_inbook_title=Postphenomenological Methodologies: New Ways in Mediating Techno-Human Relationships;">
<meta name="citation_reference" content="citation_title=Actor Network Theory and Material Semiotics;,citation_author=John Law;,citation_editor=Bryan S. Turner;,citation_publication_date=2009-03;,citation_cover_date=2009-03;,citation_year=2009;,citation_doi=10.1002/9781444304992.ch7;,citation_isbn=978-1-4443-0499-2 978-1-4051-6900-4;,citation_language=en-US;,citation_inbook_title=The New Blackwell Companion to Social Theory;">
<meta name="citation_reference" content="citation_title=Introduction to Posthuman Inquiry;,citation_abstract=We reflect on the many digital and nondigital things that support and shepherd today’s professional practices. Things are not inert objects, but vital entities implicated in the co-constitution and becoming of our everyday worlds. We forward posthumanism as a theoretical framework to address our twenty-first century situation. Actor-Network Theory, phenomenology, and related methodological approaches used throughout the book are presented. Differences between objects and things are considered. We propose interviewing objects as a way to give things a voice in research, and thus include them as participants in inquiry. Eight heuristics are introduced for conducting posthuman research.;,citation_author=Catherine Adams;,citation_author=Terrie Lynn Thompson;,citation_editor=Catherine Adams;,citation_editor=Terrie Lynn Thompson;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1057/978-1-137-57162-5_1;,citation_isbn=978-1-137-57162-5;,citation_language=en-US;,citation_inbook_title=Researching a Posthuman World: Interviews with Digital Objects;">
<meta name="citation_reference" content="citation_title=What is Technology?;,citation_abstract=In the late 20th century, there is only one thing most people agree about concerning technology – it is important. It is discussed almost as much as the weather, and sometimes it seems, with as little effect. But what is ’technology?’ If we look with even a little care, we find this same word is being used to represent things, actions, processes, methods and systems. ’Technology’ is also used symbolically as an epithet, for important working procedures, and to represent progress. This much conflict within the usage of one of our central terms won’t do; it can lead only to chaos. Even more important, the current vague use of the word ’technology’ hides from view two central concepts,and a central pattern of human behavior that we must have to make sense of our views of many critical questions in the current world including how we understand innovation, how we can communicate across Snow’s culture gap, and how we understand the way in which we humans make our living on the planet.;,citation_author=Stephen J Kline;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_volume=1;,citation_journal_title=Bulletin of Science, Technology &amp;amp;amp; Society;">
<meta name="citation_reference" content="citation_title=A Phenomenology of Technics;,citation_author=Don Ihde;,citation_editor=Robert C. Scharff;,citation_editor=Val Dusek;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_isbn=978-1-118-54725-0;,citation_inbook_title=Philosophy of Technology;">
<meta name="citation_reference" content="citation_title=Cyborg intentionality: Rethinking the phenomenology of human-technology relations;,citation_abstract=Abstract This article investigates the types of intentionality involved in humantechnology relations. It aims to augment Don Ihdes analysis of the relations between human beings and technological artifacts, by analyzing a number of concrete examples at the limits of Ihdes analysis. The article distinguishes and analyzes three types of cyborg intentionality, which all involve specific blends of the human and the technological. Technologically mediated intentionality occurs when human intentionality takes place through technological artifacts; hybrid intentionality occurs when the technological actually merges with the human; and composite intentionality is the addition of human intentionality and the intentionality of technological artifacts.;,citation_author=Peter Paul Verbeek;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_doi=10.1007/s11097-008-9099-x;,citation_isbn=1568-7759;,citation_issn=15687759;,citation_pmid=8419293;,citation_volume=7;,citation_journal_title=Phenomenology and the Cognitive Sciences;">
<meta name="citation_reference" content="citation_title=Doing Postphenomenology in Education;,citation_author=Catherine Adams;,citation_author=Joni Turville;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_isbn=978-1-4985-4523-5;,citation_inbook_title=Postphenomenological Methodologies: New Ways in Mediating Techno-Human Relationships;">
<meta name="citation_reference" content="citation_title=A Field Guide to Postphenomenology;,citation_author=Robert Rosenberger;,citation_author=Peter-Paul Verbeek;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_isbn=978-0-7391-9436-2;,citation_language=en-US;,citation_inbook_title=Postphenomenological Investigations: Essays on Human-Technology Relations;,citation_series_title=Postphenomenology and the Philosophy of Technology;">
<meta name="citation_reference" content="citation_title=Researching a Posthuman World: Interviews with Digital Objects;,citation_author=Catherine Adams;,citation_author=Terrie Lynn Thompson;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1057/978-1-137-57162-5;,citation_isbn=978-1-137-57161-8;">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title"><p><img align="center" width="75%" src="lab.png"></p></h1>
  <p class="subtitle"></p><p><span style="font-size: 150%">A Philosophy of Technology and Education in the Metaverse</span><br></p><p></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<br><strong>Ryan Straight, Ph.D</strong><br> 
</div>
        <p class="quarto-title-affiliation">
            College of Applied Science and Technology<br>University of Arizona
          </p>
    </div>
</div>

</section>
<section>
<section id="agenda" class="title-slide slide level1 center" data-menu-title="Agenda" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">OUR AGENDA</span></p>
</section>
<section id="the-plan-for-today" class="slide level2">
<h2>The Plan for Today</h2>
<div class="columns">
<div class="column" style="width:70%;">
<ol type="1">
<li>Introduction</li>
<li>Technology</li>
<li>Mediation</li>
<li>Metaverse</li>
<li>Education</li>
<li>Intersection</li>
</ol>
</div><div class="column" style="width:30%;">
<p><img data-src="https://media0.giphy.com/media/knYCcmy9DEz3G/giphy.gif?cid=ecf05e471uilqnl2czryglld7yke10d3xskcv98a4e8j0kuh&amp;rid=giphy.gif&amp;ct=g"></p>
</div>
</div>
<aside class="notes">
<ul>
<li>We’re talking about technology, so we’re going to actually try to define it before we move onto the content. This will be more valuable than you probably imagine.</li>
<li>We’re talking education, so let’s all get on the same page with the kind of conceptualization we’re exploring: ostensibly, it’s an epistemic issue. That is, it deals with how we know things and how we <em>know</em> we know things.<br>
</li>
<li>Ironically, since we’re talking philosophy and the two main approaches we’re taking to understand how technologies mediate our experiences in a technological space, we’re looking at postphenomenology (<span class="citation" data-cites="adamsDoingPostphenomenologyEducation2018">(<a href="#/references" role="doc-biblioref" onclick="">Adams and Turville 2018</a>)</span>) and touching on both Actor-Network Theory <span class="citation" data-cites="lawActorNetworkTheory2009">(<a href="#/references" role="doc-biblioref" onclick="">Law 2009</a>)</span> and posthuman inquiry <span class="citation" data-cites="adamsIntroductionPosthumanInquiry2016">(<a href="#/references" role="doc-biblioref" onclick="">Adams and Thompson 2016a</a>)</span> to help us understand how our experience of the world is altered because of this and, in turn, how we can use this to understand how new technologies like Web3 interact with and impact education.</li>
<li>Interestingly, it’s frankly somewhat irresponsible to talk about these spaces without considering the ethics centered and satellite to them, but since we’re already dealing with three of the major traditional branches of philosophy, we’ll leave that for another session. (Next year, perhaps?)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="who" class="title-slide slide level1 center" data-menu-title="Introduction" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">WHO</span></p>
</section>
<section id="ryan-straight" class="slide level2 smaller" data-menu-title="Ryan Straight">
<h2></h2>

<img data-src="https://ryanstraight.com/profile.jpg" class="r-stretch quarto-figure-center"><p><strong>Ryan Straight, Ph.D</strong><br>
Honors/Associate Professor of Practice Applied Computing &amp; Cyber Operations<br>
Director, MA{VR}X Lab<br>
College of Applied Science and Technology<br>
University of Arizona</p>
<aside class="notes">
<ul>
<li>Me, what I teach, et cetera.</li>
<li>Today’s session will essentially serve as a primer to introduce folks in the Ed3 space to the more philosophical side of things. I’ll do my best to keep things concise and provide clear utility, but it <em>will</em> necessarily be <em>somewhat</em> theoretical.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="technology" class="title-slide slide level1 center" data-menu-title="Technology" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">TECHNOLOGY</span></p>
</section>
<section id="what-is-technology" class="slide level2">
<h2>What is Technology?</h2>
<div>
<p>“Web3 is amazing&nbsp;<span class="rn">technology</span>!”</p>
<ol type="1">
<li class="fragment">Hardware or artifacts</li>
<li class="fragment">Sociotechnical system of manufacture</li>
<li class="fragment">Knowledge, technique, know-how, or methodology</li>
<li class="fragment">Sociotechnical system of use</li>
</ol>
</div>
<aside class="notes">
<p>So let’s address these one at a time. Why? Think about this phrase: “Web3 is amazing technology.” Can you, just at first blush, determine which <em>technology</em> is being referred to? Exactly.</p>
<h3 id="hardware-or-artifacts">Hardware or Artifacts</h3>
<p>Possible denotation: non-natural objects, of all kinds, manufactured by humans.</p>
<p>Kline <span class="citation" data-cites="klineWhatTechnology1985">(<a href="#/references" role="doc-biblioref" onclick="">1985</a>)</span> says, “Engineers often call manufactured articles ‘hardware;’ anthropologists usually call them ‘artifacts.’</p>
<h3 id="sociotechnical-system-of-manufacture">Sociotechnical System of Manufacture</h3>
<p>Possible denotation: All the elements needed to manufacture a particular kind of hardware, the complete working system including its inputs: people; machinery; resources; processes; and legal, economic, political and physical environment.</p>
<p>It is “much more than just the machinery and the people” but is the synergistic totality of these elements.</p>
<h3 id="knowledge-technique-know-how-or-methodology">Knowledge, Technique, Know-how, or Methodology</h3>
<p>The information, skills, processes, and procedures for accomplishing tasks. It is just what it sounds like. The best example of this is probably the classic <em>Six Million Dollar Man</em> introduction:</p>
<blockquote>
<p>Steve Austin, astronaut. A man barely alive. Gentlemen, we can rebuild him. <strong>We have the technology</strong>. We have the capability to build the world’s first bionic man. Steve Austin will be that man. Better than he was before. Better, stronger, faster.” — The Six Million Dollar Man, Opening Narration.</p>
</blockquote>
<p>So, not just the hardware, not just the ability, but <em>the know-how to accomplish the task</em>.</p>
<h3 id="a-sociotechnical-system-of-use">A Sociotechnical System of Use</h3>
<p>A system using combinations of hardware, people (and usually other elements) to accomplish tasks that humans cannot perform unaided by such systems – to extend human capacities.</p>
<ul>
<li>Example that is most pertinent to us: “We build microscopes, telescopes, cat-scanners, thermometers, and other instruments and utilize them in systems to extend our ability to sense various aspects of the world around us.”</li>
<li>It’s not just “the system” but what the system allows us to do.</li>
<li>We wouldn’t know how to create a band without the knowledge that comes from and after creating an instrument.</li>
<li>“Without sociotechnical system of use, the manufacture of hardware would have no purpose.”</li>
</ul>
<p>Folks often have difficulty even describing what Web3 is, right? Perhaps this is why. Now let’s return to our question: when we say, “Web3 is amazing technology,” does it change how you understand the question, itself? Something to ponder.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="mediation" class="title-slide slide level1 center" data-menu-title="Mediation" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">MEDIATION</span></p>
<aside class="notes">
<p>This brings us to “technological mediation.” What does that even mean? Some examples may shed light:</p>
<p>The Original Four</p>
<p>Don Ihde <span class="citation" data-cites="Ihde2014">(<a href="#/references" role="doc-biblioref" onclick="">2014</a>)</span>, in his attempt to reconcile the “classical” phenomenology that came from the likes of Edmund Husserl, Maurice Merleau-Ponty, and Martin Heidegger with our technologically immersed existence, proposed a new version of phenomenology, a post-phenomenological approach. This “post” prefix is more akin to postmodernism rather than posthumous or postmortem, in that it refers to simply the next logical step rather than something that necessarily comes <em>after</em>. It is worth mentioning here that when Ihde was exploring this new paradigm, it was the 1970s, so consider “technology” (in all its forms discussed earlier) now and half a century ago.</p>
<p>Regardless, through his ponderings he decided upon four different “technics,” as he called them, or <em>ways technology mediate our experiences</em>. As he says, “Instruments are the means by which unspoken things ‘speak’, and unseen things become ‘visible.’” They are relational and include intention, which we’ll come back to in a minute. So, briefly, what are they?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="embodiment" class="slide level2 smaller">
<h2>Embodiment</h2>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>(human – technology) → world</p>
</blockquote>
<p>People and technology together relate to the world.</p>
<ul>
<li>You see <strong>through</strong> a telescope.</li>
<li>You talk <strong>through</strong> a phone.</li>
<li>There is technologic <strong>transparency</strong>.</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="width:100%;height:0;padding-bottom:100%;position:relative;">
<iframe src="https://giphy.com/embed/gIxBtRsuxT0iWuBDY4" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/planets-telescope-mastertingus-gIxBtRsuxT0iWuBDY4">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>Here, the person more or less incorporates the technology into their outward, physical, proprioreceptory experience. A classic example is a blind cane. The cane, in essence, becomes an extension of themselves and their perception. Likewise, glasses or a telescope.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hermeneutic" class="slide level2 smaller">
<h2>Hermeneutic</h2>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>human → (technology – world)</p>
</blockquote>
<ul>
<li>You <strong>read off</strong> a speedometer.</li>
<li>We <strong>interpret</strong> an x-ray.</li>
<li>We assume the translation is accurate.</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="width:100%;height:0;padding-bottom:100%;position:relative;">
<iframe src="https://giphy.com/embed/zt0ZkDZXMEOS4" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/trippy-person-knee-zt0ZkDZXMEOS4">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>The hermeneutic relation, on the otherhand, involves <em>translating</em> or <em>interpreting</em> technology in order to understand the world. You essentially <em>read through</em> the artifact, such as a speedometer or a clock. Writing, itself, is a technology that falls within this category. (Kline, remember?)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="alterity" class="slide level2 smaller">
<h2>Alterity</h2>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>human → technology (world)</p>
</blockquote>
<ul>
<li>Technology as <strong>other</strong>.</li>
<li>We’re in <strong>its</strong> system, not ours.</li>
<li>World <strong>withdraws</strong>; we focus on the <strong>technology</strong>.</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="width:75%;height:0;padding-bottom:129%;position:relative;">
<iframe src="https://giphy.com/embed/VVAiHiDKeUHC0" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/digital-evolution-amazon-VVAiHiDKeUHC0">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>In the alterity relation, the technological artifact is treated as itself, what Ihde deemed the “quasi-other.” This ranges from a blender to an Amazon Echo to a fully functioning robot.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="background" class="slide level2 smaller">
<h2>Background</h2>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>human → (technology / world)</p>
</blockquote>
<ul>
<li>Impacts our <strong>environment</strong>.</li>
<li>Through this, <strong>us</strong>.</li>
<li>Often don’t notice until it <strong>breaks</strong>.</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="width:100%;height:0;padding-bottom:100%;position:relative;">
<iframe src="https://giphy.com/embed/Rf4SBc9erYPaLlOA0U" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/summer-drip-ac-unit-Rf4SBc9erYPaLlOA0U">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>Finally, the background relation describes experiences like an air conditioner: this is technology that influences and impacts the world around you but you have little to no interaction with. It happens <em>in the background</em>, surprising enough.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="butwaitmore" class="title-slide slide level1 center" data-menu-title="But Wait, There's More" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">BUT WAIT THERE’S MORE</span></p>
<aside class="notes">
<p>Later, other relations were beginning to be identified as technology changed and the <em>distance</em> and <em>intention</em> from and with us changed, as well. For example Verbeek <span class="citation" data-cites="verbeekCyborgIntentionalityRethinking2008">(<a href="#/references" role="doc-biblioref" onclick="">2008</a>)</span> describes a few new and necessary <em>hybrid intentionalities</em>:</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-next-generation" class="slide level2">
<h2>The Next Generation</h2>
<h3 id="fusioncyborg"><span class="rn" data-rn-type="underline" data-rn-color="red" data-rn-index="1">Fusion/Cyborg</span></h3>
<blockquote>
<p>( human / technology ) → world</p>
</blockquote>
<h3 id="composite"><span class="rn" data-rn-type="underline" data-rn-color="red" data-rn-index="2">Composite</span></h3>
<blockquote>
<p>human → ( technology → world )</p>
</blockquote>
<h3 id="augmentation"><span class="rn" data-rn-type="underline" data-rn-color="red" data-rn-index="3">Augmentation</span></h3>
<blockquote>
<p>( human – technology ) → world <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↘ ( technology – world )</p>
</blockquote>
<aside class="notes">
<p>Here we start getting into more complex relations that you can imagine being used in cutting-edge or future online/virtual learning environments. Hopefully you’re beginning to see where I’m going with all this.</p>
<ul>
<li>First, <strong>fusion</strong> or a <strong>cyborg</strong> intentionality. Here we’re talking about everything from IUDs to pacemakers, from implanted RFID chips to cochlear implants. In this case, there is no physical separation of the self and the technology. In fact, removing one of them from the equation breaks the entire thing down. A pacemaker without a user has no impact, and a user without a pacermaker is… well. You get the point. The person and the technology are literally <strong>fused</strong> insofar as experiencing the world is concerned.</li>
<li><strong>Composite</strong> intentionality: <code>Human -&gt; ( Technology -&gt; World )</code>, wherein a person’s intention is directed toward the technology, and that technology’s <em>intention</em> is thereby directed at the world. While a thermometer <em>represents</em> the temperature in the hermeneutic relation, A thermal camera, for example, which translates a world we cannot naturally perceive (infrared radiation) into something we can (a colorful video) in the composite relation.</li>
<li><strong>Augmented</strong> intentionality: considerably more complex, it includes a kind of feedback loop, wherein the human’s intention directs the technology experience the world, the results of which are then fed back to the human and the cycle repeats itself. So, not only is the human experiencing the world through the technology, the human is also experiencing the technology’s experience of the world overlaid, and reacts to <em>that</em>.</li>
</ul>
<p>The question, then, is how many of these different kind of technological relations can you identify in this experience, alone, much less in the myriad “technologies” (remember Kline?) that make up Web3 in general.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="metaverse" class="title-slide slide level1 center" data-menu-title="Metaverse" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">METAVERSE</span></p>
<aside class="notes">
<p>Beyond relationships and intention, we can conclude that between the Human and the World, the Technology will necessarily have some sort of <em>mediating effect</em>. Now, we run into some complications here, right?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="mediation-in-the-metaverse" class="slide level2">
<h2>Mediation in the Metaverse</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li class="fragment">Technological mediation is <strong>necessarily present</strong>.</li>
<li class="fragment">You <em>are</em> your avatar.</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="width:75%;height:0;padding-bottom:100%;position:relative;">
<iframe src="https://giphy.com/embed/qCOnTkTaRiAgoOEXAg" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/WeAreFitXR-vr-dancing-dance-qCOnTkTaRiAgoOEXAg">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>First, literally every experience you have in and through the metaverse is mediated by and through some technology. It’s a necessary case in that context. Now consider the complexity of of that technology. The “metaverse,” <em>in toto</em>, is <em>itself</em> an actor in this mashup of intentionalities. The metaverse–and any degree of extended or mixed realities, really–is a filter for others, a translation in ways that are well beyond our control, even though we may be the target. The subject, the object, the mediation that connects them, are all co-constituted through the experiential process.</p>
<p>Second, once we begin incorporating digital identities–wherein, as far as the world is concerned, <em>you</em> and the <em>all-encompassing digital representation of you</em>, are one and the same–this mediation becomes even more important to consider.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="not-neutral" class="slide level2">
<h2>Not Neutral</h2>
<div class="columns">
<div class="column" style="width:70%;">
<ul>
<li class="fragment">Who designed the platform you’re using? For whom?</li>
<li class="fragment">Who designed the devices you’re using? For whom?</li>
<li class="fragment">What affordances or friction is there?</li>
<li class="fragment">Does engaging through this medium actually <em>invite</em> anything unintentional and undesired?</li>
<li class="fragment">What are the impacts of these?</li>
</ul>
</div><div class="column" style="width:30%;">
<div style="width:100%;height:0;padding-bottom:178%;position:relative;">
<iframe src="https://giphy.com/embed/bjwl5xmuzCQQpMnrK4" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/kochstrasse-hannover-agencylife-agenturleben-bjwl5xmuzCQQpMnrK4">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p><strong>This process is not neutral</strong>. This is <strong>key</strong>. The pathway between you and the “other” you are engaging with, whether that is a person or simply some collection of information, is not some transparent wormhole through which unadulterated, unfiltered data is fed. There will <em>always</em> be some alteration.</p>
<ul>
<li>Who designed the platform you’re using? For whom?</li>
<li>Who designed the devices you’re using? For whom?</li>
<li>What affordances or friction is there?</li>
<li>Does engaging through this medium actually <em>invite</em> anything unintentional and undesired?</li>
<li>What are the impacts of these?</li>
</ul>
<p>Each “actor” or intentional step we introduce to this network introduces <em>another</em> intention. These can be complementary, supplementary, contradictory, or mutually exclusive, but <em>never</em> neutral.</p>
<p>If one of the points of educat<em>ing</em> and educat<em>ion</em> is to reach truths and explore those truths (small-t truths), this obviously needs to be considered in the fundamental way your experiences and even reality (and the experiences and reality of those at the other end of the interaction) are changing. This is especially true in the case of immersive technologies, as they are, cognitively-speaking, <em>very</em> convincing. This goes <em>well</em> beyond just the interface.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="education" class="title-slide slide level1 center" data-menu-title="Education" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">EDUCATION</span></p>
<aside class="notes">
<p>Bringing It All Together: Where Does Education Fit In?</p>
<p>So, while we can clearly see how, through a hermeneutic relation, a speedometer can mediate your experience of driving a car, for example, what happens when the goal of your interaction is <em>learning</em>?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="doing-postphenomenology" class="slide level2">
<h2>Doing Postphenomenology</h2>
<blockquote>
<p>… in education involves attending to the unique differences a particular technology makes to teaching practice, knowledge apprehension, and pedagogical meaning.</p>
</blockquote>
<div class="fragment">
<p>But what about the <strong>digital self</strong>?</p>
<aside class="notes">
<p>As Adams and Turville <span class="citation" data-cites="adamsDoingPostphenomenologyEducation2018">(<a href="#/references" role="doc-biblioref" onclick="">2018</a>)</span> point out, “Doing postphenomenology in education involves attending to the unique differences a particular technology makes to teaching practice, knowledge apprehension, and pedagogical meaning” (p.&nbsp;20). The question then becomes, in this new version of technologically-mediated learning <em>and of self</em>, what are these Web3 paradigms of teaching practice, knowledge apprehension, and pedagogical meaning?</p>
<p>Approaching learning in this way–that is, through a postphenomenological, posthuman inquiry lens–encourages us to scrape away at the outer encompassing veneer of the <em>digital self</em> and critically examine the delineation therein, harkening back to the traditional phenomenological “way in.” Crucially, <em>doing</em> postphenomenology has no actual, agreed-upon method <span class="citation" data-cites="rosenbergerFieldGuidePostphenomenology2015">(<a href="#/references" role="doc-biblioref" onclick="">Rosenberger and Verbeek 2015</a>)</span>. There are a variety of <em>suggested</em> heuristics <span class="citation" data-cites="adamsResearchingPosthumanWorld2016">(<a href="#/references" role="doc-biblioref" onclick="">Adams and Thompson 2016b</a>)</span>, but no hard-and-fast checklist or guide.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="approaches" class="slide level2">
<h2>Approaches</h2>
<div class="columns">
<div class="column" style="width:70%;">
<ol type="1">
<li class="fragment">Variational method or analysis</li>
<li class="fragment">Variational cross-examination</li>
<li class="fragment">Case study</li>
<li class="fragment">Conversational analysis</li>
</ol>
</div><div class="column" style="width:30%;">
<div style="width:100%;height:0;padding-bottom:100%;position:relative;">
<iframe src="https://giphy.com/embed/2WUkAVDzuQbUA" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/line-cube-shapes-2WUkAVDzuQbUA">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>That said, there are a couple approaches we can take:</p>
<ol type="1">
<li>Variational method or analysis: described as “the method of brainstorming stabilities of a multistable technology.” Remember, everything is also something else.</li>
<li>Variational cross-examination: first determining what a particular technology’s “dominant” stability is, we can move on to critically examining and identifying alternatives by exploring, for example, habits of users or frequent qualities teased out of the technology itself, its role in a particular system (thinking back to it being just an actor in a network of actors), and what we are probably most comfortable with or at least what we tend to do in this Web3 space: what’s known as “tailoring,” or “the … alterations of technology for different purposes.” Just think about how often we approach things in this space that way: “this has potential; how can we use it?”</li>
<li>Third, case study: generally speaking the postphenomenological approach is this. The Ed3DAO, for example, is a perfect candidate for this kind of approach, but so is something like the various platforms focusing on self-sovereign identity and data portability like Disco.</li>
<li>Finally, conversational analysis. This can be a little heady, but it can help us bridge the gap between simply exploring “what things do” and those mediations of our perceptions and actions “from within.”</li>
</ol>
<p>So, again, as you can see, there is no hard and fast, prescriptive method to take. This, perhaps surprisingly, works in our favor. It requires the educator and researcher to delve deep to fully understand something that they likely never will, only the individual instance of the thing. In doing so, however, incorporating the posthuman inquiry approach, we can interview these objects–whether tangible devices, virtual worlds, or digital personas–and give them time to “speak.” We musn’t simply explore how, for example, students “use” these things; we must conversely look at how those things use <em>them</em>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="intersection" class="title-slide slide level1 center" data-menu-title="Intersection" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">INTERSECTION</span></p>
</section>
<section id="an-illustration" class="slide level2">
<h2>An Illustration</h2>
<div class="cell" data-reveal="true">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-1">graph LR
&nbsp; &nbsp; subgraph Person A
&nbsp; &nbsp; A[/User\] --- B1[Environment]
&nbsp; &nbsp; B1 --- B[Device]
&nbsp; &nbsp; B --- C[Software]
&nbsp; &nbsp; C --- D[Fidelity]
&nbsp; &nbsp; D --- E[Avatar]
&nbsp; &nbsp; end
&nbsp; &nbsp; subgraph Person B
&nbsp; &nbsp; E ---|Space and Context| F[Avatar]
&nbsp; &nbsp; F --- G[Fidelity]
&nbsp; &nbsp; G --- H[Software]
&nbsp; &nbsp; H --- I[Device]
&nbsp; &nbsp; I --- J[Environment]
&nbsp; &nbsp; J --- K[/User\]
&nbsp; &nbsp; end
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<div class="fragment">
<blockquote>
<p>We are what we pretend to be, so we must be careful about what we pretend to be.</p>
</blockquote>
<aside class="notes">
<p>Between each user is a mirrored collection of mediations: the physical environment, the device and peripherals they’re using, the software itself, their network, audio, and graphical fidelity, the avatar they’ve chosen, and then the space this is all taking place in. All of this relies on the underlying infrastructure like broadband access and even simply electricity. That’s nothing to speak of the technological know-how needed to engage in these experiences to begin with.</p>
<p>Complicating this are a variety of logistical, structural, and cultural variables: language, cultural norms, social cues, even physical handicaps or less savory qualities brough to bear like bigotry, racism, misogyny, or homophobia. Think back to embodiment: we <em>become</em> our avatars. Maybe not explicitly to ourselves and perhaps our avatars are not meant to be an outwardly representation of ourselves, but is that how it is perceived? If our digital selves are so inextricably linked with who we are, is there <em>truly</em> a difference to those on the outside looking in? One is reminded of the Kurt Vonnegut quote:</p>
<blockquote>
<p>We are what we pretend to be, so we must be careful about what we pretend to be.</p>
</blockquote>
<p>In short, the deeper we fall down the immersive, Web3 rabbit hole, the further we get from being able to fully trust that the learning experience we expect a student to have is the one we envision, especially when there other individuals are involved.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="learning-in-the-metaverse-terrible-drawing" class="slide level2">
<h2>Learning in the Metaverse: Terrible Drawing</h2>
<img data-src="drawing.png" class="r-stretch">
</section>
<section id="learning-in-the-metaverse-mermaid" class="slide level2">
<h2>Learning in the Metaverse: Mermaid</h2>
<div class="cell" data-reveal="true">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-2">graph LR
&nbsp; &nbsp; subgraph Person A
&nbsp; &nbsp; A[/User\] --- B1[Environment]
&nbsp; &nbsp; B1 --- B[Device]
&nbsp; &nbsp; B --- C[Software]
&nbsp; &nbsp; C --- D[Fidelity]
&nbsp; &nbsp; D --- E[Avatar]
&nbsp; &nbsp; end
&nbsp; &nbsp; subgraph Learning Objective
&nbsp; &nbsp; E ---|Space and Context| F[Presentation]
&nbsp; &nbsp; F --- G[Fidelity]
&nbsp; &nbsp; G --- H[Software]
&nbsp; &nbsp; H --- I[Skill]
&nbsp; &nbsp; I --- J[Source]
&nbsp; &nbsp; J --- K[/Content\]
&nbsp; &nbsp; end
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<aside class="notes">
<p>Finally, let’s take our (highly complex if very ugly) diagram and tweak it to explore interpersonal metaversal interactions to learning in, through, and with these technologies.</p>
<p>Let’s imagine Person B is actually a Learning Objective (LO). Try to identify all the various actors in this network. All the different intentions, mediations, filters, lenses, and so on, that the–stepping back into our epistemological and phenomenological combo approach–sits between the learner and the, let’s say, “pure content.”</p>
<p>By way of illustration, compare a face-to-face conversation with someone and the myriad ways that can go (you can see body language, hear inflection, physical props, even, and so on) versus via text message or email. The latter collapse all the subtleties of the in-person communication and, through the constrictions and affordances of that technology, can fundamentally alter the nature of the underlying and, let’s say, “original” content. And that’s just a text message.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="back-to-the-technology" class="slide level2">
<h2>Back to the Technology</h2>
<div style="width:100%;height:0;padding-bottom:54%;position:relative;">
<iframe src="https://giphy.com/embed/116wwYf3ajIvrG" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/technology-hd-gifsremastered-116wwYf3ajIvrG">via GIPHY</a>
</p>
<aside class="notes">
<p>The key to understanding this space, the Ed3 space, where incredible technology (thanks, Kline!) comes careening into an astronomically complex notion like learning, is a hybrid approach. We spend a good deal of time discussing symbolic meaning and potential–and rightfully so. But that’s only half the story. We must also approach this space with an eye on virtual materiality. That is, where a traditional postphenomenological approach will look at objects and “what they do,” we must also approach Web3 the same way. Not simply in optimistic terms of what potential that technology has, but what changes emerge within us as a result of interaction with it. More importantly, learning from the starry-eyed mistakes made by educational technologists of the past (of which, I am certainly one and imminently guilty), and equally approaching with an eye on breakdown of the network.</p>
<p>When we approach learning in the metaverse, whether speaking of it as a general Web3-based landscape or a specific virtual, immersive experience, the entirety of the Web3 <em>technology</em> is involved in knowledge creation and information transmission, to say nothing of mediation. Understanding it to the point of being able to apply knowledge and predict affordances and consequences is a virtual (pun intended) necessity.</p>
<p>So, is this a completely fleshed-out understanding? Absolutely not. It may never be. Understanding the lived experiences of someone immediately in front of you is, from a phenomenological standpoint, impossible. Combine this with technologies we are only beginning to understand and appreciate, and we begin seeing why having a firm philosophical and methodological foundation is so important.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="but-how" class="slide level2">
<h2>But How?</h2>
<div class="columns">
<div class="column" style="width:75%;">
<ol type="1">
<li class="fragment">Composing Anecdotes through Self-Observation</li>
<li class="fragment">Gathering Lived Experience Descriptions through Interviews</li>
<li class="fragment">Composing Anecdotes through Observation of Others</li>
<li class="fragment">Finally, Studying Breakdowns and the Eidetic Reduction</li>
</ol>
</div><div class="column" style="width:25%;">
<div style="width:100%;height:0;padding-bottom:83%;position:relative;">
<iframe src="https://giphy.com/embed/ounv1hey86r5DM6WhP" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen="">
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/theoffice-episode-13-the-office-tv-ounv1hey86r5DM6WhP">via GIPHY</a>
</p>
</div>
</div>
<aside class="notes">
<p>Accordingly, here are some ideas of ways you, too, can begin attempting to exploring this space and, if you spend time educating or being educated, the crossroads as well, as described by Adams and Turville.</p>
<ol type="1">
<li>Composing Anecdotes through Self-Observation
<ol type="1">
<li>Approach your own experiences and lifeworld with “non-intrusive observation of oneself” … and the “invitational appeals of one’s equipmental or technology-textured surround.”</li>
<li>This is harder than it sounds. “Explanations, opinions, judgments, or theoretical concepts must be pushed aside in favor of what was given in the moment.”</li>
</ol></li>
<li>Gathering Lived Experience Descriptions through Interviews
<ol type="1">
<li>Perhaps not the most easily accomplished approach, to be fair, especially for those that aren’t necessarily in an environment where that kind of research is encouraged or even permissible.</li>
<li>That said, this may be a tremendously revealing process, especially when directed toward teachers and learners in metaversal spaces.</li>
<li>This should <strong>not</strong> be confused with user experience testing, of course. When gathering these lived experience descriptions, while the design choices made by software developers may have an influential and mediating impact as discussed early, it is merely one step to overcome to get to the real experience.</li>
</ol></li>
<li>Composing Anecdotes through Observation of Others
<ol type="1">
<li>Contrasting the interview approach, simply observing others in the space can also lead to revelations without overt disturbance.</li>
<li>It may, for example, “assist in pointing up aspects of everyday life that may otherwise be taken for granted by oneself and others.”</li>
<li>However, it’s important to note that, since through the observation you may not access a truly sufficient and representative lived experience (you can imagine just how much you would miss by watching someone’s actions and not being privy to their motivations or goals).</li>
</ol></li>
<li>Finally, Studying Breakdowns and the Eidetic Reduction
<ol type="1">
<li>Recall Heidegger and his broken hammer. In this approach, we come <em>after</em>. That is, instead of trying to tease out the lived experiences <em>in vivo</em>, it is the breakdown of the moment that gives us access.</li>
<li>For example, in this very space, it is easier to understand how people and things interact when there is friction than when it goes smoothly.</li>
<li>Likewise, for a completely non-technical and more Heideggerian example: when your pencil or chalk breaks mid-thought.</li>
</ol></li>
</ol>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="conclusion" class="title-slide slide level1 center" data-menu-title="Conclusion" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">CONCLUSION</span></p>
</section>
<section id="to-reiterate" class="slide level2 smaller">
<h2>To Reiterate</h2>
<blockquote>
<p>Doing postphenomenology in education involves attending to the unique differences a particular technology makes to teaching practice, knowledge apprehension, and pedagogical methods.” (p.&nbsp;21)</p>
</blockquote>
<div>
<ul>
<li class="fragment">We <em>embody</em> our digital selves.</li>
<li class="fragment">We <em>interpret</em> incoming information.</li>
<li class="fragment">We treat the metaverse and devices <em>as objects, themselves</em>.</li>
<li class="fragment">Our digital selves are permanently <em>in the background</em>.</li>
<li class="fragment">It will become impossible to divorce <em>ourselves</em> from our <em>selves</em>.</li>
<li class="fragment">We are equally <em>on</em> and <em>in</em> the loop.</li>
</ul>
</div>
<aside class="notes">
<p>To wrap up, I’d like to quote Adams and Turville one last time:</p>
<blockquote>
<p>Doing postphenomenology in education involves attending to the unique differences a particular technology makes to teaching practice, knowledge apprehension, and pedagogical methods.” (p.&nbsp;21)</p>
</blockquote>
<p>I suggest that this is a) accurate, and b) insufficient when Web3 is said technology (and again, by “technology” here I mean all of Kline’s definitions thereof). When approaching Web3, we interact with the technology itself through virtually all of the different relations, as well, simultaneously.</p>
<ul>
<li>We <em>embody</em> our digital selves to the point that there is no meaningful difference between the two.</li>
<li>We <em>interpret</em> (hermeneutic) the myriad data and information streaming toward us, whether this is “on chain” or simply “in the metaverse.”</li>
<li>We treat the metaverse and the devices through which we access and interact with it <em>as objects themselves</em> (alterity), so care must be taken in how we do so and what our choices can ultimately mean for others.</li>
<li>Along with embodying our digital selves, in a world where our actions, credentials, and identity are permanently and immutably accessible, we are, in effect, always present <em>in the background</em>.</li>
<li>One could argue that, given how inseparable our selves and our digital selves are, this actually moves beyond <em>embodiment</em> and approaches a <em>cyborg</em> intentionality.</li>
<li>Any sort of virtual, immersive world, when presenting us with information, content, even abilities that we lack otherwise, also arguably falls within a <em>composite</em> and <em>augmented</em> relationship with the world. We are equally <em>on</em> and <em>in</em> the loop.</li>
</ul>
<p>But, as we all know, the tool is just a tool at the end of the day. Hopefully, the content I’ve shared today will help us moving forward to remember that the <em>people</em> are the key. This is <em>good work</em>; good, hard, and necessary.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="the-end" class="title-slide slide level1 center" data-menu-title="The End" data-background="#9EABAE" data-background-image="lab.png" data-background-size="35%" data-background-position="right 5% top 5%">
<h1></h1>
<p><span class="r-fit-text">THE END</span></p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-adamsIntroductionPosthumanInquiry2016" class="csl-entry" role="doc-biblioentry">
Adams, Catherine, and Terrie Lynn Thompson. 2016a. <span>“Introduction to <span>Posthuman Inquiry</span>.”</span> In <em>Researching a <span>Posthuman World</span>: <span>Interviews</span> with <span>Digital Objects</span></em>, edited by Catherine Adams and Terrie Lynn Thompson, 1–22. <span>London</span>: <span>Palgrave Macmillan UK</span>. <a href="https://doi.org/10.1057/978-1-137-57162-5_1">https://doi.org/10.1057/978-1-137-57162-5_1</a>.
</div>
<div id="ref-adamsResearchingPosthumanWorld2016" class="csl-entry" role="doc-biblioentry">
———. 2016b. <em>Researching a <span>Posthuman World</span>: <span>Interviews</span> with <span>Digital Objects</span></em>. <span>London</span>: <span>Springer Nature</span>. <a href="https://doi.org/10.1057/978-1-137-57162-5">https://doi.org/10.1057/978-1-137-57162-5</a>.
</div>
<div id="ref-adamsDoingPostphenomenologyEducation2018" class="csl-entry" role="doc-biblioentry">
Adams, Catherine, and Joni Turville. 2018. <span>“Doing <span>Postphenomenology</span> in <span>Education</span>.”</span> In <em>Postphenomenological <span>Methodologies</span>: <span>New Ways</span> in <span>Mediating Techno-Human Relationships</span></em>, 3–25. <span>Lexington, Maryland</span>: <span>Lexington Books</span>.
</div>
<div id="ref-Ihde2014" class="csl-entry" role="doc-biblioentry">
Ihde, Don. 2014. <span>“A <span>Phenomenology</span> of <span>Technics</span>.”</span> In <em>Philosophy of <span>Technology</span></em>, edited by Robert C. Scharff and Val Dusek, Second, 539–60. <span>Chichester, West Sussex, UK</span>: <span>Wiley-Blackwell</span>.
</div>
<div id="ref-klineWhatTechnology1985" class="csl-entry" role="doc-biblioentry">
Kline, Stephen J. 1985. <span>“What Is <span>Technology</span>?”</span> <em>Bulletin of Science, Technology &amp; Society</em> 1: 215–18.
</div>
<div id="ref-lawActorNetworkTheory2009" class="csl-entry" role="doc-biblioentry">
Law, John. 2009. <span>“Actor <span>Network Theory</span> and <span>Material Semiotics</span>.”</span> In <em>The <span>New Blackwell Companion</span> to <span>Social Theory</span></em>, edited by Bryan S. Turner, 141–58. <span>Oxford, UK</span>: <span>Wiley-Blackwell</span>. <a href="https://doi.org/10.1002/9781444304992.ch7">https://doi.org/10.1002/9781444304992.ch7</a>.
</div>
<div id="ref-rosenbergerFieldGuidePostphenomenology2015" class="csl-entry" role="doc-biblioentry">
Rosenberger, Robert, and Peter-Paul Verbeek. 2015. <span>“A <span>Field Guide</span> to <span>Postphenomenology</span>.”</span> In <em>Postphenomenological <span>Investigations</span>: <span>Essays</span> on <span>Human-Technology Relations</span></em>. Postphenomenology and the <span>Philosophy</span> of <span>Technology</span>. <span>Lexington Books</span>.
</div>
<div id="ref-verbeekCyborgIntentionalityRethinking2008" class="csl-entry" role="doc-biblioentry">
Verbeek, Peter Paul. 2008. <span>“Cyborg Intentionality: <span>Rethinking</span> the Phenomenology of Human-Technology Relations.”</span> <em>Phenomenology and the Cognitive Sciences</em> 7 (3): 387–95. <a href="https://doi.org/10.1007/s11097-008-9099-x">https://doi.org/10.1007/s11097-008-9099-x</a>.
</div>
</div>
</section>
<section id="thats-a-wrap" class="slide level2">
<h2>That’s a wrap!</h2>
<p>Thank you for coming! Find out more at:</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="mavrx-lab">MA{VR}X Lab</h3>
<p><a href="https://mavrxlab.org" class="uri">https://mavrxlab.org</a><br>
<a href="https://ryanstraight.com" class="uri">https://ryanstraight.com</a></p>
<p><img data-src="rs.png"></p>
</div><div class="column" style="width:50%;">

</div>
</div>

<p><img src="lab.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>Dr.&nbsp;Ryan Straight – ryanstraight@arizona.edu – @ryanstraight@hci.social</p>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../../site_libs/revealjs/plugin/multiplex/socket.io.js"></script>
  <script src="../../../site_libs/revealjs/plugin/multiplex/multiplex.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"theme":"whiteboard","boardmarkerWidth":5},
'multiplex': {"secret":"16682901044416022790","id":"608d0caa4c64700a","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'print',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>